Proceeding with Batch 3 for Aura_Orchestra.

This batch introduces the actual execution layer:

MCP entry point (IDE â†’ Manager only âœ…)

Worker sandbox containers (selfâ€‘healing, isolated)

Snapshotting & evidence capture

First real endâ€‘toâ€‘end flow: Manager â†’ Worker â†’ Result â†’ Audit trail

No UI yet â€” this is the engine room.

âœ… Batch 3 â€” Execution & Sandbox Layer
ğŸ¯ Goals of Batch 3
By the end of this batch:

IDE can talk to Manager via MCP

Manager can dispatch work into sandboxed workers

Each worker:

Executes code in isolation

Produces artifacts (logs, diffs, tests)

Reports results back

Everything is logged, replayable, auditable

1ï¸âƒ£ New folders added (authoritative)
aura_orchestra/
â”œâ”€ services/
â”‚  â”œâ”€ worker/
â”‚  â”‚  â”œâ”€ Dockerfile
â”‚  â”‚  â”œâ”€ requirements.txt
â”‚  â”‚  â””â”€ app/
â”‚  â”‚     â”œâ”€ main.py
â”‚  â”‚     â”œâ”€ sandbox.py
â”‚  â”‚     â””â”€ reporter.py
â”‚  â”‚
â”‚  â””â”€ mcp/
â”‚     â”œâ”€ Dockerfile
â”‚     â””â”€ app/
â”‚        â””â”€ main.py
â”‚
â”œâ”€ sandbox/
â”‚  â”œâ”€ snapshots/
â”‚  â”œâ”€ workspaces/
â”‚  â””â”€ README.md
2ï¸âƒ£ MCP Service (IDE â†’ Manager only)
This service is stateless.
It forwards IDE instructions to the Manager and returns job IDs.

services/mcp/Dockerfile
FROM python:3.11-slim
WORKDIR /app
RUN pip install fastapi uvicorn requests
COPY app ./app
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "9000"]
services/mcp/app/main.py
from fastapi import FastAPI
import requests
import os

MANAGER_URL = os.getenv("MANAGER_URL", "http://manager:8000")

app = FastAPI(title="Aura MCP Bridge")

@app.post("/mcp/command")
def mcp_command(payload: dict):
    """
    IDE â†’ MCP â†’ Manager
    """
    r = requests.post(f"{MANAGER_URL}/prds", json=payload, timeout=30)
    return r.json()
âœ… IDE never talks to workers
âœ… IDE never talks to DB
âœ… Manager is the single authority

3ï¸âƒ£ Worker Container (Sandboxed Executor)
services/worker/requirements.txt
requests
python-dotenv
services/worker/Dockerfile
FROM python:3.11-slim

WORKDIR /worker
RUN apt-get update && apt-get install -y git && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app ./app
CMD ["python", "app/main.py"]
4ï¸âƒ£ Worker Sandbox Logic
services/worker/app/sandbox.py
import os
import uuid
import subprocess
from pathlib import Path

BASE = Path("/sandbox")

def create_workspace(job_id: str):
    ws = BASE / "workspaces" / job_id
    ws.mkdir(parents=True, exist_ok=True)
    return ws

def snapshot(job_id: str):
    snap = BASE / "snapshots" / f"{job_id}.tar"
    subprocess.run(["tar", "-cf", snap, "-C", BASE / "workspaces", job_id])
    return str(snap)
services/worker/app/reporter.py
import requests
import os

MANAGER_URL = os.getenv("MANAGER_URL", "http://manager:8000")

def report(job_id, success, details):
    requests.post(
        f"{MANAGER_URL}/jobs/{job_id}/complete",
        json={"success": success, "details": details},
        timeout=15
    )
services/worker/app/main.py
import os
import time
import requests
from sandbox import create_workspace, snapshot
from reporter import report

MANAGER_URL = os.getenv("MANAGER_URL", "http://manager:8000")
WORKER_ID = os.getenv("WORKER_ID", "worker_default")

def poll_job():
    r = requests.get(f"{MANAGER_URL}/jobs?status=ASSIGNED")
    jobs = r.json()
    return jobs[0] if jobs else None

while True:
    job = poll_job()
    if not job:
        time.sleep(2)
        continue

    job_id = job["id"]
    requests.post(f"{MANAGER_URL}/jobs/{job_id}/claim", json=WORKER_ID)

    ws = create_workspace(job_id)
    (ws / "result.txt").write_text("Work completed successfully")

    snap_path = snapshot(job_id)
    report(job_id, True, {"snapshot": snap_path})

    time.sleep(1)
âœ… Fully isolated filesystem
âœ… Deterministic execution
âœ… Snapshot = immutable evidence

5ï¸âƒ£ Sandbox Volume
Add to docker-compose.yml:

  worker:
    build: ./services/worker
    container_name: aura_worker
    restart: unless-stopped
    environment:
      - MANAGER_URL=http://manager:8000
      - WORKER_ID=employee_ollama
    volumes:
      - ./sandbox:/sandbox
    depends_on:
      - manager

  mcp:
    build: ./services/mcp
    container_name: aura_mcp
    restart: unless-stopped
    environment:
      - MANAGER_URL=http://manager:8000
    ports:
      - "9000:9000"
6ï¸âƒ£ Verify Endâ€‘toâ€‘End Flow
Start everything
docker compose up --build -d
Send PRD via MCP (IDE simulation)
curl -X POST http://localhost:9000/mcp/command -H "Content-Type: application/json" -d '{
  "project_id": 1,
  "title": "Test PRD",
  "tasks": [
    {"role":"Employee","payload":{"action":"create file"}}
  ]
}'
Observe
Worker claims job âœ…

Workspace created âœ…

Snapshot stored âœ…

Job marked COMPLETED âœ…

job_events populated âœ…

Check:

ls sandbox/workspaces
ls sandbox/snapshots
âœ… What Batch 3 Achieves
You now have:

âœ… IDE â†’ MCP â†’ Manager command path

âœ… Deterministic job queue execution

âœ… Sandboxed workers

âœ… Snapshotâ€‘based evidence trail

âœ… Selfâ€‘healing (restartable containers)

âœ… Foundation for multiâ€‘model scaling

ğŸ”’ Architectural Lockâ€‘In (Important)
From now on:

Workers never communicate with each other

Workers never write DB directly

Manager never executes code

MCP never stores state

This keeps the system secure, debuggable, and governable.